---
title: "TRAVAIL DE SESSION – ÉTUDE DE CAS"
subtitle: "MATH60611 - Méthodes avancées en exploitation de données"
author: "Alfred Assal et James Roy"
date: "`r Sys.Date()`"
geometry: margin=1.5cm
output:
  # bookdown::html_document2:
  #   toc: yes
  #   number_sections: yes
  #   toc_float:
  #     collapsed: no
  # #   toc_depth: '3'
  bookdown::pdf_document2:
    toc: yes
    toc_depth: 1
    extra_dependencies: ["flafter"]
params:
  created_date: "2023-09-12"
header-includes:
- \usepackage{float}
- \usepackage{amsmath}
- \usepackage{ragged2e}
---


L’objectif de votre mandat est de fournir à la ville un classement des 1864 intersections
en termes de sécurité (des plus dangereuses aux moins dangereuses), afin qu’elle puisse
prioriser les intersections les plus à risque dans le but d’améliorer les infrastructures.

Votre analyse devra se baser sur une modélisation des accidents observés dans les 10
dernières années (variable acc)

```{r}
library(tidyverse)
library(glmnet)
library(grpreg)
library(rpart)
library(randomForest)
library(lubridate)
library(sf)
library(leaflet)
library(RColorBrewer)
library(rpart.plot)
library(randomForest)
library(caret)
library(fastDummies)
```


```{r}
dat = read.csv("data_final.csv", sep = ";")
```

```{r}
var_fact = c("all_pedest", "median", "green_stra", "half_phase", "any_ped_pr", "ped_countd", "lt_protect", "lt_restric", "lt_prot_re", "any_exclus", "borough", "curb_exten", "all_red_an", "new_half_r")

dat = dat %>% dplyr::select(-c("street_1", "street_2", "X", "X.1", "rue_1", "rue_2", "date_", "x", "y"))
#dat$date_ = as.Date(dat$date_, "%d/%m/%Y")
dat = dat %>% 
  mutate_at(vars(var_fact), as.factor)

dat[["ln_distdt"]] = ifelse(is.na(dat[["ln_distdt"]]), 0, as.numeric(dat[["ln_distdt"]]))
```
```{r}
datdum=dummy_cols(dat, remove_first_dummy=TRUE, remove_selected_columns=TRUE)
```


```{r}
dat = dat %>% mutate(check = ifelse(cli == 0 & cri == 0 & cti == 0, 1,0))

dat_check = dat[dat$check==1,]

dat = dat %>% 
    mutate(pi = if_else(check == 1, median(dat$pi), pi),
         cri = if_else(check == 1, median(dat$cri), cri),
         cli = if_else(check == 1, median(dat$cli), cli),
         cti = if_else(check == 1, median(dat$cti), cti),
         ln_cti = if_else(check == 1, median(dat$ln_cti), ln_cti),
         ln_cli = if_else(check == 1, median(dat$ln_cli), ln_cli),
         ln_cri = if_else(check == 1, median(dat$ln_cri), ln_cri))

#dat_test = dat %>% mutate(test = fli+fri+fti)
#summary(dat_test[,c("test", "fi")])
# Test pour voir s'il y a des incohérences...
```

```{r}
set.seed(489565)
ntrain=615
ntest=nrow(dat)-ntrain
indtrain=sample(1:nrow(dat),ntrain,replace=FALSE)
```

```{r}
xdum=datdum
xdum$acc=NULL
xdum=as.matrix(xdum)
dattrain=dat[indtrain,]
dattest=dat[-indtrain,]
datdumtrain=datdum[indtrain,]
datdumtest=datdum[-indtrain,]
xdumtrain=xdum[indtrain,]
xdumtest=xdum[-indtrain,]
```

```{r}
wrapglmnet=function(xtrain,ytrain,xtest,ytest=NULL,alpha)
{
library(glmnet)
par(mfrow=c(2,2))
plot(glmnet(x=xtrain,y=ytrain,alpha=alpha),xvar = "lambda", label = TRUE)
cv=cv.glmnet(x=xtrain,y=ytrain, alpha=alpha)
plot(cv)
pred=predict(cv,new=xtest,s="lambda.min")
pred1se=predict(cv,new=xtest,s="lambda.1se")
err=NA
if(!is.null(ytest))
{
plot(ytest,pred)
plot(ytest,pred1se)
err=data.frame(mean(abs(pred-ytest)),mean((pred-ytest)^2),
mean(abs(pred1se-ytest)),mean((pred1se-ytest)^2))
names(err)=c("MAE", "MSE", "MAE_1SE","MSE_1SE")
}
co=predict(cv,s="lambda.min",type="coefficients")
co=as.matrix(co)
co=co[co[,1] != 0,,drop=FALSE]
co1se=predict(cv,s="lambda.1se",type="coefficients")
co1se=as.matrix(co1se)
co1se=co1se[co1se[,1] != 0,,drop=FALSE]
out=list(err,co,co1se,pred,pred1se)
names(out)=c("error","coef","coef1se","pred","pred1se")
out
}
```


```{r}
lmfit=lm(acc~.,data=datdumtrain)
predlmfit=predict(lmfit,newdata=datdumtest)

errlmfit=data.frame(mean(abs(predlmfit-datdumtest$acc)),mean((predlmfit-datdumtest$acc)^2))
names(errlmfit)=c("MAE","MSE")
errlmfit
```


```{r}
lasso=wrapglmnet(xdumtrain,datdumtrain$acc,xdumtest, datdumtest$acc,1)
dim(lasso$coef)

lasso$error
```

```{r}
ridge=wrapglmnet(xdumtrain,datdumtrain$acc,xdumtest, datdumtest$acc,0)

dim(ridge$coef)

ridge$error
```

```{r}
cv.relax=cv.glmnet(x=xdumtrain,y=datdumtrain$acc, alpha=1,relax=TRUE)
plot(cv.relax)
```

```{r}
pred=predict(cv.relax,new=xdumtest,s="lambda.min",gamma="gamma.min")
ytest=datdumtest$acc
errlassrel=data.frame(MAE=mean(abs(pred-ytest)),MSE=mean((pred-ytest)^2))
errlassrel
```
```{r}
group=c(1:50,rep(53,27))
grlassofit=grpreg(xdumtrain, datdumtrain$acc, group, penalty="grLasso")
plot(grlassofit)

grlassofitcv=cv.grpreg(xdumtrain, datdumtrain$acc, group,seed=1234,penalty="grLasso")
coefgrlasso=predict(grlassofitcv,type="coefficients")
predgrlasso=predict(grlassofitcv,X=xdumtest)
errgrlasso=data.frame(mean(abs(predgrlasso-datdumtest$acc)),mean((predgrlasso-datdumtest$acc)^2))
names(errgrlasso)=c("MAE","MSE")
row.names(errgrlasso)=c("group lasso")
```

```{r}
gelcv=cv.grpreg(xdumtrain, datdumtrain$acc, group, seed=1234,penalty="gel")
coefgel=predict(gelcv,type="coefficients")
predgel=predict(gelcv,X=xdumtest)
errgel=data.frame(mean(abs(predgel-datdumtest$acc)),mean((predgel-datdumtest$acc)^2))
names(errgel)=c("MAE","MSE")
row.names(errgel)=c("exponential lasso")
errgel

```

```{r}
rptree=rpart(acc~.,data=dattrain,method="anova",control = rpart.control(xval = 10, minsplit=10, minbucket = 3, cp = 0))
rptreepruned=prune(rptree,cp=rptree$cp[which.min(rptree$cp[,"xerror"]),"CP"])
predrpart=predict(rptreepruned,newdata=dattest)
errrpart=data.frame(mean(abs(predrpart-datdumtest$acc)),mean((predrpart-datdumtest$acc)^2))
names(errrpart)=c("MAE","MSE")
row.names(errrpart)=c("single tree (rpart)")
errrpart
```

```{r}
rf=randomForest(acc~.,data=dattrain,ntree=500)
predrf=predict(rf,newdata=dattest)
errrf=data.frame(mean(abs(predrf-datdumtest$acc)),mean((predrf-datdumtest$acc)^2))
names(errrf)=c("MAE","MSE")
row.names(errrf)=c("random forest")
errrf

virf = importance(rf)
varImpPlot(rf)
```


```{r}
allres=rbind(lasso$err[,1:2],ridge$err[,1:2],errlmfit,errlassrel[,1:2])
row.names(allres)=c("lasso","ridge","OLS","relaxed lasso")
allres=rbind(allres,errgrlasso)
allres=rbind(allres,errgel)
allres=rbind(allres,errrpart)
allres=rbind(allres,errrf)
allres[order(allres[,1]),]
```


------- 

```{r}
# variable qui joue sur les accidents ou le risque
facteur_risque <- c(
  "acc",
  "all_pedest",
  "ln_cli",
  "ln_cri",
  "ln_cti",
  #"pi",
  #"fli",
  #"fri",
  #"fti",
  "ln_pi",
  "ln_fli",
  "ln_fri",
  "ln_fti",
  "tot_crossw",
  "number_of_",
  "avg_crossw",
  "tot_road_w",
  "median",
  "green_stra",
  "any_ped_pr",
  "ped_countd",
  "lt_protect",
  "lt_restric",
  "lt_prot_re",
  "parking",
  "total_lane",
  "of_exclusi",
  "any_exclus",
  "commercial",
  "curb_exten",
  "all_red_an",
  "new_half_r",
  "ln_distdt"
  #"distdt"
)
```


```{r}
mod = lm(acc ~ ., data = dat[, facteur_risque, drop = FALSE])
summary(mod)
```

boxplot
```{r}



is_numeric_or_factor <- function(x) { is.numeric(x) || is.factor(x) }

numeric_or_factor_vars <- sapply(dat, is_numeric_or_factor)


#numeric_or_factor_vars <- numeric_or_factor_vars[-(1:3)]

data_numeric_or_factor <- dat[, numeric_or_factor_vars]


for(var in names(data_numeric_or_factor)) {
  if(is.factor(dat[[var]])) {
    # count plot au lieu de box_plot pour les facteur
    p <- ggplot(dat, aes_string(x = var)) +
      geom_bar() +
      labs(title = paste("Compte de", var), x = var)
  } else {
    # boxplot pour les numérique
    p <- ggplot(dat, aes_string(y = var)) +
      geom_boxplot() +
      labs(title = paste("Boxplot de", var), y = var)
  }
  print(p)
}


```

regarder les combinaisons linéaire possible
```{r}
dat_num = dat[,7:20]

for (col in names(dat_num)) {
  dat_num[[col]] <- as.numeric(dat_num[[col]])
}

#columns_to_remove <- grep("^ln", names(dat_num))

# Supprimer les colonnes commençant par "ln"
#dat_num <- dat_num[, -columns_to_remove]

dat_num = as.data.frame(scale(dat_num))


dat_fa = factanal(dat_num, factors = 2, na.action = )


```

visualisation de tous les regression linéaire simple
```{r}
for (var_name in names(dat)) {
  if (is.numeric(dat[[var_name]])) {
    
    formula <- as.formula(paste("acc ~", var_name))
    mod1 <- lm(formula, data = dat)
    
    plot <- ggplot(dat, aes_string(x=var_name, y="acc")) +
      geom_smooth(method = "lm") +
      geom_abline(intercept = mod1$coefficients[1], slope = mod1$coefficients[2])+
      geom_point() +
      labs(x=var_name) 
      
    print(plot)
  }
}

```
Séparation en validation et test 
```{r}
dat2 <- dat %>% 
  select(-rue_1, -rue_2, -date_, -x, -y, -int_no)

# creation de data set train et test (pas besoin de de train pcq utilise CV)
set.seed(1234)
training_indices <- createDataPartition(dat2$acc, p = 0.7, list = FALSE)
dat_train <- dat2[training_indices, ]
dat_test <- dat2[-training_indices, ]

```

arbre simple
```{r}
tree <- rpart(acc ~ ., data = dat_train,
              control = rpart.control(xval = 5, minisplit=20,minibucket=5, cp=0))

rpart.plot(tree)
tree$cptable

elague <- prune(tree, cp=tree$cp[which.min(tree$cp[, "xerror"]), "CP"])

rpart.plot(elague)

predTr <-predict(elague, newdata = dat_test)

mean((predTr-dat_test$acc)^2)


```


random forest
```{r}

set.seed(123)
rf <- randomForest(acc ~. ,data = dat_train, ntree=500)

predRF <- predict(rf,newdata = dat_test)

mean((predRF-dat_test$acc)^2)

varImpPlot(rf)

importance <- varImp(rf) %>%
  arrange(desc(Overall))
importance
```

Creation de l'indice
L'indice est mauvais, mais je voulais juste pas me casser la tete
```{r}
dat3 <- dat %>% 
  select(int_no,rue_1, rue_2,acc,cti,cli,cri,borough)

dat3 <- dummy_cols(dat3, select_columns = "borough", remove_selected_columns = TRUE)

#dat3[, 4:34] <- lapply(dat3[, 4:34], function(x) scale(x, center = T, scale = TRUE))

#dat3 <- dat3 %>% mutate(across(11:38, ~ . * 980))



# ajout des poids
manual_sum <- apply(dat3[, 7:34], 1, sum)

dat3 <- dat3 %>% mutate(indice =1587*cti + 797*cli + 633*cri)


ordre <- dat3 %>% select(acc,indice,rue_1,rue_2) %>% 
  arrange(desc(indice))

cor(dat3$acc,dat3$indice)

```






























